{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Example: Hyper-parameter Optimization\n",
        "In this example, we show the examples of using hyperopt to optimize the MLP nerwork built from Pytorch.\n",
        "\n",
        "**Features included:**\n",
        "\n",
        "1. With implementation of early stopping.\n",
        "2. With implementation of hyper-parameter tuning with hyperopt. "
      ],
      "metadata": {
        "id": "3zizjFLHzE6l"
      },
      "id": "3zizjFLHzE6l"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dRWR0FI3eSJO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRWR0FI3eSJO",
        "outputId": "a903cc2a-5439-4845-cffd-211d391dd6d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hpsklearn\n",
            "  Downloading hpsklearn-0.1.0.tar.gz (26 kB)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.7/dist-packages (from hpsklearn) (0.1.2)\n",
            "Collecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hpsklearn) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from hpsklearn) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hpsklearn) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt->hpsklearn) (1.15.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt->hpsklearn) (4.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt->hpsklearn) (2.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt->hpsklearn) (4.64.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt->hpsklearn) (0.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->hpsklearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->hpsklearn) (1.1.0)\n",
            "Building wheels for collected packages: hpsklearn\n",
            "  Building wheel for hpsklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hpsklearn: filename=hpsklearn-0.1.0-py3-none-any.whl size=23913 sha256=336e459897a8c94aa38b07d1e9f7444b8455659c4003d2e956df49f1216fc0e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/22/23/9207fbe861f70774b563f909a415b228450bfcf863c64ac1e8\n",
            "Successfully built hpsklearn\n",
            "Installing collected packages: nose, hpsklearn\n",
            "Successfully installed hpsklearn-0.1.0 nose-1.3.7\n"
          ]
        }
      ],
      "source": [
        "!pip install hpsklearn "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "15474554",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15474554",
        "outputId": "e2a51985-5c76-4107-c004-e362bc3fdf93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARN: OMP_NUM_THREADS=None =>\n",
            "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import read_csv\n",
        "import random\n",
        "\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "\n",
        "from hyperopt import hp, tpe, fmin, Trials, space_eval\n",
        "from functools import partial\n",
        "\n",
        "from hpsklearn import HyperoptEstimator\n",
        "from hpsklearn import any_classifier\n",
        "from hpsklearn import any_preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fc2555d5",
      "metadata": {
        "id": "fc2555d5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torch import Generator\n",
        "from torch import Tensor\n",
        "from torch.nn import Linear\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import Sigmoid\n",
        "from torch.nn import Module\n",
        "from torch.optim import SGD\n",
        "from torch.nn import BCELoss\n",
        "from torch.nn.init import kaiming_uniform_\n",
        "from torch.nn.init import xavier_uniform_\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "be2458f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be2458f3",
        "outputId": "e0d9c63c-7128-40f5-fbaa-af37775ad2f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# set device to CUDA if available, else to CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbe527eb",
      "metadata": {
        "id": "dbe527eb"
      },
      "source": [
        "## Hyper-parameter Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c2daa56e",
      "metadata": {
        "id": "c2daa56e"
      },
      "outputs": [],
      "source": [
        "TEST_SIZE = 0.3\n",
        "NUM_FOLDS = 5\n",
        "RANDOM_STATE = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a8196a4c",
      "metadata": {
        "id": "a8196a4c"
      },
      "outputs": [],
      "source": [
        "random.seed(RANDOM_STATE)\n",
        "torch.manual_seed(RANDOM_STATE)\n",
        "np.random.seed(RANDOM_STATE)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fba72139",
      "metadata": {
        "id": "fba72139"
      },
      "source": [
        "## Pytorch NN Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Definition"
      ],
      "metadata": {
        "id": "NknsC-zExijl"
      },
      "id": "NknsC-zExijl"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "dd01eb16",
      "metadata": {
        "id": "dd01eb16"
      },
      "outputs": [],
      "source": [
        "class CSVDataset(Dataset):\n",
        "    # load the dataset\n",
        "    def __init__(self, path):\n",
        "        # load the csv file as a dataframe\n",
        "        df = read_csv(path, header=None)\n",
        "        # store the inputs and outputs\n",
        "        self.X = df.values[:, :-1]\n",
        "        self.y = df.values[:, -1]\n",
        "        # ensure input data is floats\n",
        "        self.X = self.X.astype('float32')\n",
        "        # label encode target and ensure the values are floats\n",
        "        self.y = LabelEncoder().fit_transform(self.y)\n",
        "        self.y = self.y.astype('float32')\n",
        "        self.y = self.y.reshape((len(self.y), 1))\n",
        " \n",
        "    # number of rows in the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        " \n",
        "    # get a row at an index\n",
        "    def __getitem__(self, idx):\n",
        "        return [self.X[idx], self.y[idx]]\n",
        " \n",
        "    # get indexes for train and test rows\n",
        "    def get_splits(self, n_test, random_state):\n",
        "        # determine sizes\n",
        "        test_size = round(n_test * len(self.X))\n",
        "        train_size = len(self.X) - test_size\n",
        "        # calculate the split\n",
        "        return random_split(self, [train_size, test_size], generator=Generator().manual_seed(random_state))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Definition"
      ],
      "metadata": {
        "id": "HW5DQLA_xnBw"
      },
      "id": "HW5DQLA_xnBw"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "01b30fba",
      "metadata": {
        "id": "01b30fba"
      },
      "outputs": [],
      "source": [
        "class MLP(Module):\n",
        "    # define model elements\n",
        "    def __init__(self, n_inputs, hidden_layer1, hidden_layer2,):\n",
        "        super(MLP, self).__init__()\n",
        "        # input to first hidden layer\n",
        "        self.hidden1 = Linear(n_inputs, hidden_layer1)\n",
        "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
        "        self.act1 = ReLU()\n",
        "        # second hidden layer\n",
        "        self.hidden2 = Linear(hidden_layer1, hidden_layer2)\n",
        "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
        "        self.act2 = ReLU()\n",
        "        # third hidden layer and output\n",
        "        self.hidden3 = Linear(hidden_layer2, 1)\n",
        "        xavier_uniform_(self.hidden3.weight)\n",
        "        self.act3 = Sigmoid() # self.act3 = Softmax(dim=1) for multi-class classification\n",
        " \n",
        "    # forward propagate input\n",
        "    def forward(self, X):\n",
        "        # input to first hidden layer\n",
        "        X = self.hidden1(X)\n",
        "        X = self.act1(X)\n",
        "         # second hidden layer\n",
        "        X = self.hidden2(X)\n",
        "        X = self.act2(X)\n",
        "        # third hidden layer and output\n",
        "        X = self.hidden3(X)\n",
        "        X = self.act3(X)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f403b47c",
      "metadata": {
        "id": "f403b47c"
      },
      "outputs": [],
      "source": [
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "12bbb7c3",
      "metadata": {
        "id": "12bbb7c3"
      },
      "outputs": [],
      "source": [
        "# prepare the dataset\n",
        "def prepare_data(path):\n",
        "    # load the dataset\n",
        "    dataset = CSVDataset(path)\n",
        "    # calculate split\n",
        "    train, test = dataset.get_splits(n_test=TEST_SIZE, random_state=RANDOM_STATE)\n",
        "    # prepare data loaders\n",
        "    train_dl = DataLoader(train, batch_size=32, worker_init_fn=seed_worker, shuffle=True)\n",
        "    test_dl = DataLoader(test, batch_size=1024, worker_init_fn=seed_worker, shuffle=False)\n",
        "    return train_dl, test_dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f9c13c51",
      "metadata": {
        "id": "f9c13c51"
      },
      "outputs": [],
      "source": [
        "## for cross validation\n",
        "def reset_weights(m):\n",
        "    '''\n",
        "    Try resetting model weights to avoid\n",
        "    weight leakage.\n",
        "    '''\n",
        "    for layer in m.children():\n",
        "        if hasattr(layer, 'reset_parameters'):\n",
        "            # print(f'Reset trainable parameters of layer = {layer}')\n",
        "            layer.reset_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "Define the hyper-parameter dict PARA, and feed PARA into the train_model function."
      ],
      "metadata": {
        "id": "PLi7prMdxrye"
      },
      "id": "PLi7prMdxrye"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "843f3c9e",
      "metadata": {
        "id": "843f3c9e"
      },
      "outputs": [],
      "source": [
        "# train the model\n",
        "def train_model(train_dl, valid_dl, PARA, epochs=100, patience=10, early_stopping=False, cross_valid=False):\n",
        "    \n",
        "    ######################################\n",
        "    # variables declaration for hyperopt #\n",
        "    ######################################\n",
        "    \n",
        "    LR = PARA['lr']\n",
        "    MOMENTUM = PARA['momentum']\n",
        "    HIDDEN_LYR1 = PARA['hidden_layer1']\n",
        "    HIDDEN_LYR2 = PARA['hidden_layer2']\n",
        "    \n",
        "    ###########################################\n",
        "    # variables declaration for early stopping#\n",
        "    ###########################################\n",
        "    \n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = []\n",
        "    \n",
        "    # initialize for early stopping\n",
        "    epochs_no_improve = 0\n",
        "    min_val_loss = np.Inf\n",
        "    early_stop_detected = False\n",
        "    \n",
        "    ###############################\n",
        "    # model related implementation#\n",
        "    ###############################\n",
        "    \n",
        "    # define the model\n",
        "    model = MLP(60, HIDDEN_LYR1, HIDDEN_LYR2)\n",
        "    if cross_valid:\n",
        "        model.apply(reset_weights)\n",
        "        \n",
        "    # define the optimization\n",
        "    criterion = BCELoss() # CrossEntropyLoss() for multi-class classification\n",
        "    optimizer = SGD(model.parameters(), lr=LR, momentum=MOMENTUM)\n",
        "    \n",
        "    # enumerate epochs\n",
        "    for epoch in range(1, epochs+1):\n",
        "        \n",
        "        # prepare model for training\n",
        "        model.train() \n",
        "        # enumerate mini batches\n",
        "        for i, (inputs, targets) in enumerate(train_dl):\n",
        "            # clear the gradients\n",
        "            optimizer.zero_grad()\n",
        "            # compute the model output\n",
        "            y_pred_train = model(inputs)\n",
        "            # calculate loss\n",
        "            loss = criterion(y_pred_train, targets)\n",
        "            # credit assignment\n",
        "            loss.backward()\n",
        "            # update model weights\n",
        "            optimizer.step()\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "            \n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch \n",
        "        train_loss = np.average(train_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        \n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        \n",
        "        epoch_len = len(str(epochs))\n",
        "        \n",
        "        if valid_dl is None:\n",
        "        \n",
        "            print_msg = (f'[{epoch:>{epoch_len}}/{epochs:>{epoch_len}}] ' +\n",
        "                             f'train_loss: {train_loss:.5f} ')\n",
        "            \n",
        "            print(print_msg)\n",
        "        \n",
        "        # process valid set if it is available\n",
        "        else:\n",
        "            # prepare model for evaluation\n",
        "            model.eval() \n",
        "\n",
        "            for inputs, targets in valid_dl:\n",
        "                # forward pass: compute predicted outputs by passing inputs to the model\n",
        "                y_pred_valid = model(inputs)\n",
        "                # calculate the loss\n",
        "                loss = criterion(y_pred_valid, targets)\n",
        "                # record validation loss\n",
        "                valid_losses.append(loss.item())\n",
        "\n",
        "            # print training/validation statistics \n",
        "            # calculate average loss over an epoch            \n",
        "            valid_loss = np.average(valid_losses)\n",
        "            avg_valid_losses.append(valid_loss)\n",
        "\n",
        "            print_msg = (f'[{epoch:>{epoch_len}}/{epochs:>{epoch_len}}] ' +\n",
        "                         f'train_loss: {train_loss:.5f} ' +\n",
        "                         f'valid_loss: {valid_loss:.5f}')\n",
        "\n",
        "            # print(print_msg)\n",
        "\n",
        "            # clear lists to track next epoch\n",
        "            valid_losses = []\n",
        "\n",
        "            if early_stopping:\n",
        "\n",
        "                # early_stopping needs the validation loss to check if it has decresed\n",
        "                if valid_loss < min_val_loss:\n",
        "                    epochs_no_improve = 0\n",
        "                    min_val_loss = valid_loss\n",
        "                else:\n",
        "                    epochs_no_improve += 1\n",
        "\n",
        "                if epoch > 5 and epochs_no_improve==patience:\n",
        "                    early_stop_detected = True\n",
        "                    break\n",
        "                \n",
        "    #     if early_stopping:\n",
        "    #         if early_stop_detected:\n",
        "    #             print(f'  Early stopping at epoch: {epoch}!' )\n",
        "    #             print(f'  Stopped with valid loss={valid_loss:.5f}')\n",
        "    #         else:\n",
        "    #             print(f'  No early stopping. Finish training until epoch: {epoch}!' )\n",
        "    #             print(f'  Stopped with valid loss={valid_loss:.5f}')    \n",
        "\n",
        "    return model, avg_train_losses, avg_valid_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "IyFgZ527xvVm"
      },
      "id": "IyFgZ527xvVm"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3118542f",
      "metadata": {
        "id": "3118542f"
      },
      "outputs": [],
      "source": [
        "# evaluate the model\n",
        "def evaluate_model(model, test_dl):\n",
        "    predictions, actuals = list(), list()\n",
        "    # prep model for evaluation\n",
        "    model.eval() \n",
        "    for i, (inputs, targets) in enumerate(test_dl):\n",
        "        # evaluate the model on the test set\n",
        "        y_proba = model(inputs)\n",
        "        # retrieve numpy array\n",
        "        y_proba = y_proba.detach().numpy()\n",
        "        # round to class values\n",
        "        y_pred = y_proba.round()\n",
        "        # extract true label\n",
        "        y_true = targets.numpy()\n",
        "        y_true = y_true.reshape((len(y_true), 1))\n",
        "        # store\n",
        "        predictions.append(y_pred)\n",
        "        actuals.append(y_true)\n",
        "    predictions, actuals = np.vstack(predictions), np.vstack(actuals)\n",
        "    # calculate f1-score\n",
        "    f1 = f1_score(actuals, predictions)\n",
        "    return f1, actuals, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "849691be",
      "metadata": {
        "id": "849691be"
      },
      "outputs": [],
      "source": [
        "# make a class prediction for one row of data\n",
        "def predict(row, model):\n",
        "    # make prediction\n",
        "    y_proba = model(row)\n",
        "    # retrieve numpy array\n",
        "    y_proba = y_proba.detach().numpy()\n",
        "    y_pred = y_proba.round() # np.argmax(y_proba) for multi-class classification\n",
        "    return y_proba, y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objective Function Definition\n",
        "Return the metric to evaluate the hyper-paramter settings."
      ],
      "metadata": {
        "id": "YcOfvCJPx-wL"
      },
      "id": "YcOfvCJPx-wL"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "95eb58b6",
      "metadata": {
        "id": "95eb58b6"
      },
      "outputs": [],
      "source": [
        "def objective(params):\n",
        "    \n",
        "    print ('Params testing: ', params)\n",
        "    print ('\\n ')\n",
        "    \n",
        "    # Define the K-fold Cross Validator\n",
        "    kfold = KFold(n_splits=NUM_FOLDS, shuffle=True)\n",
        "    scores = []\n",
        "\n",
        "    # K-fold Cross Validation model evaluation\n",
        "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(train_dl.dataset)):\n",
        "\n",
        "        random.shuffle(train_ids)\n",
        "        \n",
        "        # Sample elements randomly from a given list of ids, no replacement.\n",
        "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "        valid_subsampler = torch.utils.data.SubsetRandomSampler(valid_ids)\n",
        "\n",
        "        # Define data loaders for training and testing data in this fold\n",
        "        trainloader = torch.utils.data.DataLoader(\n",
        "                          train_dl.dataset, \n",
        "                          batch_size=10, sampler=train_subsampler)\n",
        "        validloader = torch.utils.data.DataLoader(\n",
        "                          train_dl.dataset,\n",
        "                          batch_size=10, sampler=valid_subsampler)\n",
        "    \n",
        "        # Train Model\n",
        "        model, avg_train_losses, avg_valid_losses = train_model(train_dl=trainloader, \n",
        "                                                                valid_dl=validloader, \n",
        "                                                                PARA=params,\n",
        "                                                                early_stopping=True, \n",
        "                                                                cross_valid=True)\n",
        "     \n",
        "        #predict the test set \n",
        "        f1, _, _ = evaluate_model(model, validloader)\n",
        "        # print('F1 score: %.3f' % f1)\n",
        "        scores.append(f1)\n",
        "        \n",
        "    mean = round(sum(scores)/len(scores), 3)\n",
        "    print('Mean F1 score from cross validation: %.3f' % mean)\n",
        "    \n",
        "    return -mean"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper-parameter Optimization\n",
        "Here we use TPE from hyperopt to optimize the hyper-parameters."
      ],
      "metadata": {
        "id": "TYSNSS-Ex00d"
      },
      "id": "TYSNSS-Ex00d"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f9331000",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9331000",
        "outputId": "feed9d21-5b60-419e-cd95-501cec9d6d14",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146 62\n",
            "Params testing: \n",
            "{'hidden_layer1': 10, 'hidden_layer2': 5, 'lr': 0.0001, 'momentum': 0.3}\n",
            "Mean F1 score from cross validation: 0.292\n",
            "Params testing: \n",
            "{'hidden_layer1': 10, 'hidden_layer2': 20, 'lr': 0.001, 'momentum': 0.9}\n",
            "Mean F1 score from cross validation: 0.425\n",
            "Params testing: \n",
            "{'hidden_layer1': 10, 'hidden_layer2': 8, 'lr': 0.0001, 'momentum': 0.5}\n",
            "Mean F1 score from cross validation: 0.324\n",
            "Params testing: \n",
            "{'hidden_layer1': 10, 'hidden_layer2': 20, 'lr': 0.001, 'momentum': 0.3}\n",
            "Mean F1 score from cross validation: 0.414\n",
            "Params testing: \n",
            "{'hidden_layer1': 20, 'hidden_layer2': 20, 'lr': 0.001, 'momentum': 0.5}\n",
            "Mean F1 score from cross validation: 0.432\n",
            "Params testing: \n",
            "{'hidden_layer1': 10, 'hidden_layer2': 20, 'lr': 0.0001, 'momentum': 0.5}\n",
            "Mean F1 score from cross validation: 0.406\n",
            "Params testing: \n",
            "{'hidden_layer1': 20, 'hidden_layer2': 10, 'lr': 0.0001, 'momentum': 0.5}\n",
            "Mean F1 score from cross validation: 0.525\n",
            "Params testing: \n",
            "{'hidden_layer1': 20, 'hidden_layer2': 8, 'lr': 0.01, 'momentum': 0.3}\n",
            "Mean F1 score from cross validation: 0.627\n",
            "Params testing: \n",
            "{'hidden_layer1': 20, 'hidden_layer2': 10, 'lr': 0.01, 'momentum': 0.9}\n",
            "Mean F1 score from cross validation: 0.626\n",
            "Params testing: \n",
            "{'hidden_layer1': 20, 'hidden_layer2': 10, 'lr': 0.0001, 'momentum': 0.8}\n",
            "Mean F1 score from cross validation: 0.417\n",
            "Params testing: \n",
            "{'hidden_layer1': 30, 'hidden_layer2': 5, 'lr': 0.0001, 'momentum': 0.9}\n",
            "Mean F1 score from cross validation: 0.564\n",
            "Params testing: \n",
            "{'hidden_layer1': 20, 'hidden_layer2': 10, 'lr': 0.0001, 'momentum': 0.5}\n",
            "Mean F1 score from cross validation: 0.117\n",
            "Params testing: \n",
            "{'hidden_layer1': 20, 'hidden_layer2': 20, 'lr': 0.0001, 'momentum': 0.3}\n",
            "Mean F1 score from cross validation: 0.506\n",
            "Params testing: \n",
            "{'hidden_layer1': 10, 'hidden_layer2': 10, 'lr': 0.0001, 'momentum': 0.3}\n",
            "Mean F1 score from cross validation: 0.387\n",
            "Params testing: \n",
            "{'hidden_layer1': 20, 'hidden_layer2': 5, 'lr': 0.0001, 'momentum': 0.9}\n",
            "Mean F1 score from cross validation: 0.259\n",
            "Params testing: \n",
            "{'hidden_layer1': 10, 'hidden_layer2': 5, 'lr': 0.001, 'momentum': 0.9}\n",
            "Mean F1 score from cross validation: 0.412\n",
            "Params testing: \n",
            "{'hidden_layer1': 30, 'hidden_layer2': 20, 'lr': 0.0001, 'momentum': 0.8}\n",
            "Mean F1 score from cross validation: 0.248\n",
            "Params testing: \n",
            "{'hidden_layer1': 20, 'hidden_layer2': 8, 'lr': 0.01, 'momentum': 0.3}\n",
            "Mean F1 score from cross validation: 0.677\n",
            "Params testing: \n",
            "{'hidden_layer1': 30, 'hidden_layer2': 20, 'lr': 0.0001, 'momentum': 0.3}\n",
            "Mean F1 score from cross validation: 0.000\n",
            "Params testing: \n",
            "{'hidden_layer1': 10, 'hidden_layer2': 8, 'lr': 0.01, 'momentum': 0.5}\n",
            "Mean F1 score from cross validation: 0.653\n",
            "100%|██████████| 20/20 [00:40<00:00,  2.01s/it, best loss: -0.677]\n",
            "Best Parameters\n",
            "{'hidden_layer1': 20, 'hidden_layer2': 8, 'lr': 0.01, 'momentum': 0.3}\n"
          ]
        }
      ],
      "source": [
        "# prepare the data\n",
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/sonar.csv'\n",
        "train_dl, test_dl = prepare_data(path)\n",
        "print(len(train_dl.dataset), len(test_dl.dataset))\n",
        "\n",
        "# hyper-parameter optimization with hyperopt\n",
        "# define space\n",
        "nn_space = {'lr' : hp.choice('lr', np.logspace(-2, -4, 3)),\n",
        "            'momentum': hp.choice('momentum', [0.3,0.5,0.8,0.9]),\n",
        "            'hidden_layer1': hp.choice('hidden_layer1', [10,20,30]),\n",
        "            'hidden_layer2': hp.choice('hidden_layer2', [5,8,10,20]),\n",
        "           }\n",
        "\n",
        "trials = Trials()\n",
        "\n",
        "# Run Hyper Optimization\n",
        "para_best = fmin(\n",
        "    fn=objective,\n",
        "    space=nn_space,\n",
        "    algo=tpe.suggest,\n",
        "    return_argmin=False,\n",
        "    verbose=True,\n",
        "    trials=trials,\n",
        "    max_evals=20,  # Max Number of Iterations\n",
        "    rstate=np.random.RandomState(0)\n",
        ")\n",
        "\n",
        "print(\"Best Parameters\")\n",
        "print(para_best)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print the best hyper-parameter settings"
      ],
      "metadata": {
        "id": "9ZD4vmEFyRq-"
      },
      "id": "9ZD4vmEFyRq-"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b3d5ca38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3d5ca38",
        "outputId": "16537cdc-8d51-4b5a-cf9f-e497554e6d0a",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hidden_layer1': 20, 'hidden_layer2': 8, 'lr': 0.01, 'momentum': 0.3}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "para_best"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traing with the best hyper-paramters"
      ],
      "metadata": {
        "id": "jrzV92Mtyi0f"
      },
      "id": "jrzV92Mtyi0f"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2faca074",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2faca074",
        "outputId": "e29dba81-eeb8-4ae6-fba0-e0ea915091a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/100] train_loss: 0.76309 \n",
            "[  2/100] train_loss: 0.73123 \n",
            "[  3/100] train_loss: 0.70712 \n",
            "[  4/100] train_loss: 0.69297 \n",
            "[  5/100] train_loss: 0.68178 \n",
            "[  6/100] train_loss: 0.67785 \n",
            "[  7/100] train_loss: 0.67145 \n",
            "[  8/100] train_loss: 0.66812 \n",
            "[  9/100] train_loss: 0.65893 \n",
            "[ 10/100] train_loss: 0.66210 \n",
            "[ 11/100] train_loss: 0.65828 \n",
            "[ 12/100] train_loss: 0.64855 \n",
            "[ 13/100] train_loss: 0.64858 \n",
            "[ 14/100] train_loss: 0.64308 \n",
            "[ 15/100] train_loss: 0.64468 \n",
            "[ 16/100] train_loss: 0.63519 \n",
            "[ 17/100] train_loss: 0.63599 \n",
            "[ 18/100] train_loss: 0.63431 \n",
            "[ 19/100] train_loss: 0.63311 \n",
            "[ 20/100] train_loss: 0.63026 \n",
            "[ 21/100] train_loss: 0.62856 \n",
            "[ 22/100] train_loss: 0.63361 \n",
            "[ 23/100] train_loss: 0.62589 \n",
            "[ 24/100] train_loss: 0.62787 \n",
            "[ 25/100] train_loss: 0.62276 \n",
            "[ 26/100] train_loss: 0.62105 \n",
            "[ 27/100] train_loss: 0.62328 \n",
            "[ 28/100] train_loss: 0.61622 \n",
            "[ 29/100] train_loss: 0.61403 \n",
            "[ 30/100] train_loss: 0.61485 \n",
            "[ 31/100] train_loss: 0.61106 \n",
            "[ 32/100] train_loss: 0.61461 \n",
            "[ 33/100] train_loss: 0.60813 \n",
            "[ 34/100] train_loss: 0.60938 \n",
            "[ 35/100] train_loss: 0.60225 \n",
            "[ 36/100] train_loss: 0.60509 \n",
            "[ 37/100] train_loss: 0.60307 \n",
            "[ 38/100] train_loss: 0.59139 \n",
            "[ 39/100] train_loss: 0.59466 \n",
            "[ 40/100] train_loss: 0.59104 \n",
            "[ 41/100] train_loss: 0.60088 \n",
            "[ 42/100] train_loss: 0.59013 \n",
            "[ 43/100] train_loss: 0.59101 \n",
            "[ 44/100] train_loss: 0.59540 \n",
            "[ 45/100] train_loss: 0.59062 \n",
            "[ 46/100] train_loss: 0.59114 \n",
            "[ 47/100] train_loss: 0.58660 \n",
            "[ 48/100] train_loss: 0.58139 \n",
            "[ 49/100] train_loss: 0.58921 \n",
            "[ 50/100] train_loss: 0.57918 \n",
            "[ 51/100] train_loss: 0.58367 \n",
            "[ 52/100] train_loss: 0.57881 \n",
            "[ 53/100] train_loss: 0.58500 \n",
            "[ 54/100] train_loss: 0.57510 \n",
            "[ 55/100] train_loss: 0.57264 \n",
            "[ 56/100] train_loss: 0.57592 \n",
            "[ 57/100] train_loss: 0.56663 \n",
            "[ 58/100] train_loss: 0.56678 \n",
            "[ 59/100] train_loss: 0.56775 \n",
            "[ 60/100] train_loss: 0.57623 \n",
            "[ 61/100] train_loss: 0.56280 \n",
            "[ 62/100] train_loss: 0.56738 \n",
            "[ 63/100] train_loss: 0.55716 \n",
            "[ 64/100] train_loss: 0.56509 \n",
            "[ 65/100] train_loss: 0.56213 \n",
            "[ 66/100] train_loss: 0.56442 \n",
            "[ 67/100] train_loss: 0.55466 \n",
            "[ 68/100] train_loss: 0.55504 \n",
            "[ 69/100] train_loss: 0.55495 \n",
            "[ 70/100] train_loss: 0.54879 \n",
            "[ 71/100] train_loss: 0.55163 \n",
            "[ 72/100] train_loss: 0.55056 \n",
            "[ 73/100] train_loss: 0.55489 \n",
            "[ 74/100] train_loss: 0.55270 \n",
            "[ 75/100] train_loss: 0.54345 \n",
            "[ 76/100] train_loss: 0.54730 \n",
            "[ 77/100] train_loss: 0.54031 \n",
            "[ 78/100] train_loss: 0.53917 \n",
            "[ 79/100] train_loss: 0.54815 \n",
            "[ 80/100] train_loss: 0.54007 \n",
            "[ 81/100] train_loss: 0.53762 \n",
            "[ 82/100] train_loss: 0.53925 \n",
            "[ 83/100] train_loss: 0.53980 \n",
            "[ 84/100] train_loss: 0.54347 \n",
            "[ 85/100] train_loss: 0.52676 \n",
            "[ 86/100] train_loss: 0.54219 \n",
            "[ 87/100] train_loss: 0.53642 \n",
            "[ 88/100] train_loss: 0.53045 \n",
            "[ 89/100] train_loss: 0.51666 \n",
            "[ 90/100] train_loss: 0.53008 \n",
            "[ 91/100] train_loss: 0.53581 \n",
            "[ 92/100] train_loss: 0.52129 \n",
            "[ 93/100] train_loss: 0.51847 \n",
            "[ 94/100] train_loss: 0.51805 \n",
            "[ 95/100] train_loss: 0.51791 \n",
            "[ 96/100] train_loss: 0.51696 \n",
            "[ 97/100] train_loss: 0.51835 \n",
            "[ 98/100] train_loss: 0.50904 \n",
            "[ 99/100] train_loss: 0.51728 \n",
            "[100/100] train_loss: 0.51199 \n",
            "Test F1-Score: 0.651\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x450 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class=1 (y_proba=0.746) vs (Actual class=1)\n"
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "model, avg_train_losses, avg_valid_losses = train_model(train_dl=train_dl, \n",
        "                                                        valid_dl=None, \n",
        "                                                        PARA=para_best,\n",
        "                                                        early_stopping=True)\n",
        "# evaluate the model\n",
        "F1_test, actuals_test, predictions_test = evaluate_model(model, test_dl)\n",
        "\n",
        "print(f\"Test F1-Score: {round(F1_test, 3)}\")\n",
        "\n",
        "# Show summary of performance\n",
        "cf_matrix = confusion_matrix(actuals_test, predictions_test)\n",
        "\n",
        "plt.figure(dpi=150, figsize=(4, 3))\n",
        "sns.heatmap(cf_matrix, annot=True)\n",
        "plt.show()\n",
        "\n",
        "# make a single prediction (expect class=1)\n",
        "for inputs, targets in test_dl:  \n",
        "    sample_X_test = inputs[0] \n",
        "    sample_y_test = targets[0]\n",
        "y_proba, y_pred = predict(sample_X_test, model)\n",
        "print('Predicted class=%d (y_proba=%.3f) vs (Actual class=%d)' % (y_pred, y_proba, sample_y_test.numpy()[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "567ff305",
      "metadata": {
        "id": "567ff305"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ab3376a",
      "metadata": {
        "id": "0ab3376a"
      },
      "source": [
        "## Reference\n",
        "\n",
        "1. https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n",
        "2. https://www.machinecurve.com/index.php/2021/02/03/how-to-use-k-fold-cross-validation-with-pytorch/\n",
        "3. https://github.com/Bjarten/early-stopping-pytorch/blob/master/MNIST_Early_Stopping_example.ipynb"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "hyperopt-pytorch-example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}